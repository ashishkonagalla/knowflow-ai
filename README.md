# ğŸ§  KnowFlow AI  
*A Retrieval-Augmented Generation (RAG) Chatbot for Your Documents*  

KnowFlow AI lets you **upload PDFs, DOCX, or TXT files** and ask natural-language questions about their content.  
It combines **OpenAI embeddings**, **FAISS vector search**, and **GPT-4o reasoning** inside a **Streamlit UI**.

---

## ğŸš€ Features
âœ… Upload and parse PDF, DOCX, or TXT  
âœ… Generate OpenAI `text-embedding-3-large` vectors  
âœ… Store vectors locally using FAISS for semantic retrieval  
âœ… Query your documents with GPT-4o grounded answers  
âœ… Citations of retrieved chunks (â€œSourcesâ€)  
âœ… Lightweight Streamlit interface â€” runs locally in minutes  

---

## ğŸ§± Architecture
```text
User Upload â†’ Text Extraction â†’ Chunking
        â†“
OpenAI Embeddings â†’ FAISS Vector Store
        â†“
Retriever (Top-k Chunks)
        â†“
GPT-4o â†’ Context-aware Answer + Sources
        â†“
Streamlit UI


---

## ğŸ—‚ï¸ Folder Structure


knowflow-ai/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py          # Keys and paths
â”‚   â”œâ”€â”€ utils.py           # Extraction + chunking
â”‚   â”œâ”€â”€ retriever.py       # Embedding + FAISS
â”‚   â”œâ”€â”€ generator.py       # GPT-4o answer logic
â”‚   â””â”€â”€ main.py            # Streamlit interface
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/               # Uploaded files
â”‚   â””â”€â”€ processed/         # FAISS index + chunks
â”‚
â”œâ”€â”€ .env                   # OPENAI_API_KEY=sk-...
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## âš™ï¸ Installation

```bash
git clone https://github.com/<your-username>/knowflow-ai.git
cd knowflow-ai
python -m venv .venv
.venv\Scripts\activate      # Windows
pip install -r requirements.txt
```

Create a `.env` file:

```bash
OPENAI_API_KEY=sk-your-key
```

---

## â–¶ï¸ Run the App

```bash
streamlit run app/main.py
```

Then open: [http://localhost:8501](http://localhost:8501)

---

## ğŸ§ª Usage

1. Upload a PDF/DOCX/TXT file in the sidebar.
2. Wait for â€œâœ… Document indexed successfully.â€
3. Type a question in the input box and click **Ask**.
4. Read your GPT-4o-generated, source-grounded answer.

---

## ğŸ’¡ Example Query

> **Question:** What AI tools did Ashish use in his latest work experience?
>
> **Answer:**
> Ashish used RAG pipelines with FAISS/Pinecone, FastAPI, LLM APIs, and semantic search.
>
> **Sources:**
> [1] Resume_AKonagalla_AI.pdf (chunk 2)

---

## ğŸ§© Tech Stack

| Layer      | Tools                           |
| ---------- | ------------------------------- |
| UI         | Streamlit                       |
| Embeddings | OpenAI `text-embedding-3-large` |
| Vector DB  | FAISS (local)                   |
| LLM        | GPT-4o                          |
| Framework  | LangChain (for FAISS wrapper)   |
| Parsing    | PyMuPDF, docx2txt               |

---

## ğŸ”’ Notes

* Only embeddings + answers are processed via OpenAI APIs.
* FAISS index and documents remain **local** to your machine.
* For free/offline demos, swap to SBERT embeddings instead.

---

## â˜ï¸ Deployment (Optional)

Deploy easily on **Railway**, **Render**, or **Hugging Face Spaces**:

```bash
railway up   # or render.yaml / spaces app
```

---

## ğŸ§¾ License

MIT License Â© 2025 Ashish Konagalla

---

## âœ¨ Acknowledgements

* [LangChain](https://www.langchain.com) for vector utilities
* [Streamlit](https://streamlit.io) for rapid UI
* [OpenAI](https://openai.com) for embeddings + LLM API
* [FAISS](https://github.com/facebookresearch/faiss) for vector search

````

---
